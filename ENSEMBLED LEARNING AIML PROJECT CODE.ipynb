{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab634e7-37b8-4ee8-ab58-dd0e7cd98185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[28  0]\n",
      " [ 0 52]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        28\n",
      "         1.0       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Bagging Accuracy: 0.99\n",
      "Stacking Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[28  0]\n",
      " [ 0 52]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        28\n",
      "         1.0       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Bagging Accuracy: 0.99\n",
      "Stacking Accuracy: 1.00\n",
      "Confusion Matrix:\n",
      "[[28  0]\n",
      " [ 0 52]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        28\n",
      "         1.0       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Bagging Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load dataset\n",
    "file_path =  df = \"C:/Users/HP/OneDrive/ドキュメント/CKD_Preprocessed.csv\"\n",
    "df= pd.read_csv(file_path)\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"Chronic Kidney Disease: yes\"])\n",
    "y = df[\"Chronic Kidney Disease: yes\"]\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Define base models (Removed SVM)\n",
    "base_models = [\n",
    "('rf', RandomForestClassifier(n_estimators=50, random_state=42)), # Reduced trees from 100 to 50\n",
    "('log_reg', LogisticRegression(max_iter=2000, solver='saga', random_state=42))]\n",
    "# Use Logistic Regression as meta-learner (faster than Decision Tree)\n",
    "meta_learner = LogisticRegression(max_iter=2000, solver='saga', random_state=42)\n",
    "# Create Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_learner, stack_method='auto')\n",
    "# Train the Stacking model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "# Evaluate Stacking model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "# Print results\n",
    "print(f\"Stacking Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "# Bagging Classifier with Decision Tree\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "# Evaluate Bagging Model\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Bagging Accuracy: {accuracy_bagging:.2f}\")\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"Chronic Kidney Disease: yes\"])\n",
    "y = df[\"Chronic Kidney Disease: yes\"]\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Define base models (Removed SVM)\n",
    "base_models = [\n",
    "('rf', RandomForestClassifier(n_estimators=50, random_state=42)), # Reduced trees from 100 to 50\n",
    "('log_reg', LogisticRegression(max_iter=2000, solver='saga', random_state=42))]\n",
    "# Use Logistic Regression as meta-learner (faster than Decision Tree)\n",
    "meta_learner = LogisticRegression(max_iter=2000, solver='saga', random_state=42)\n",
    "# Create Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_learner, stack_method='auto')\n",
    "# Train the Stacking model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "# Evaluate Stacking model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "# Print results\n",
    "print(f\"Stacking Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "# Bagging Classifier with Decision Tree\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "# Evaluate Bagging Model\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Bagging Accuracy: {accuracy_bagging:.2f}\") \n",
    "df = pd.read_csv(file_path)\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"Chronic Kidney Disease: yes\"])\n",
    "y = df[\"Chronic Kidney Disease: yes\"]\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Define base models (Removed SVM)\n",
    "base_models = [\n",
    "('rf', RandomForestClassifier(n_estimators=50, random_state=42)), # Reduced trees from 100 to 50\n",
    "('log_reg', LogisticRegression(max_iter=2000, solver='saga', random_state=42))]\n",
    "# Use Logistic Regression as meta-learner (faster than Decision Tree)\n",
    "meta_learner = LogisticRegression(max_iter=2000, solver='saga', random_state=42)\n",
    "# Create Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_learner, stack_method='auto')\n",
    "# Train the Stacking model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "# Evaluate Stacking model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "# Print results\n",
    "print(f\"Stacking Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "# Bagging Classifier with Decision Tree\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "# Evaluate Bagging Model\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Bagging Accuracy: {accuracy_bagging:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab726d4-0622-46c0-b91c-05f7b9dc7df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f8998-46ad-4dca-96a4-bd74569c89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
